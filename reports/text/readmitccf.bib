@Article{Agniel2018,
  author       = {Agniel, Denis and Kohane, Isaac S and Weber, Griffin M},
  title        = {Biases in electronic health record data due to processes within the healthcare system: retrospective observational study},
  volume       = {361},
  issn         = {0959-8138},
  doi          = {10.1136/bmj.k1479},
  eprint       = {https://www.bmj.com/content/361/bmj.k1479.full.pdf},
  url          = {https://www.bmj.com/content/361/bmj.k1479},
  abstract     = {Objective To evaluate on a large scale, across 272 common types of laboratory tests, the impact of healthcare processes on the predictive value of electronic health record (EHR) data.Design Retrospective observational study.Setting Two large hospitals in Boston, Massachusetts, with inpatient, emergency, and ambulatory care.Participants All 669 452 patients treated at the two hospitals over one year between 2005 and 2006.Main outcome measures The relative predictive accuracy of each laboratory test for three year survival, using the time of the day, day of the week, and ordering frequency of the test, compared to the value of the test result.Results The presence of a laboratory test order, regardless of any other information about the test result, has a significant association (P\&lt;0.001) with the odds of survival in 233 of 272 (86\%) tests. Data about the timing of when laboratory tests were ordered were more accurate than the test results in predicting survival in 118 of 174 tests (68\%).Conclusions Healthcare processes must be addressed and accounted for in analysis of observational health data. Without careful consideration to context, EHR data are unsuitable for many research questions. However, if explicitly modeled, the same processes that make EHR data complex can be leveraged to gain insight into patients{\textquoteright} state of health.},
  elocation-id = {k1479},
  journal      = {BMJ},
  publisher    = {BMJ Publishing Group Ltd},
  year         = {2018},
}

@article{milinovich2018extracting,
  title={Extracting and utilizing electronic health data from Epic for research},
  author={Milinovich, Alex and Kattan, Michael W},
  journal={Annals of translational medicine},
  volume={6},
  number={3},
  year={2018},
  publisher={AME Publications}
}

@Article{Allaudeen2011,
  author="Allaudeen, Nazima and Schnipper, Jeffrey L. and Orav, E. John and Wachter, Robert M. and Vidyarthi, Arpana R.",
  title="Inability of Providers to Predict Unplanned Readmissions",
  journal="Journal of General Internal Medicine",
  year="2011",
  month="Jul",
  day="01",
  volume="26",
  number="7",
  pages="771--776",
  abstract="Readmissions cause significant distress to patients and considerable financial costs. Identifying hospitalized patients at high risk for readmission is an important strategy in reducing readmissions. We aimed to evaluate how well physicians, case managers, and nurses can predict whether their older patients will be readmitted and to compare their predictions to a standardized risk tool (Probability of Repeat Admission, or Pra).",
  issn="1525-1497",
  doi="10.1007/s11606-011-1663-3",
  url="https://doi.org/10.1007/s11606-011-1663-3"
}

@Article{Artetxe2018,
  author          = {Artetxe, Arkaitz and Beristain, Andoni and Graña, Manuel},
  title           = {Predictive models for hospital readmission risk: A systematic review of methods.},
  volume          = {164},
  pages           = {49--64},
  issn            = {1872-7565},
  doi             = {10.1016/j.cmpb.2018.06.006},
  abstract        = {Hospital readmission risk prediction facilitates the identification of patients potentially at high risk so that resources can be used more efficiently in terms of cost-benefit. In this context, several models for readmission risk prediction have been proposed in recent years. The goal of this review is to give an overview of prediction models for hospital readmission, describe the data analysis methods and algorithms used for building the models, and synthesize their results. Studies that reported the predictive performance of a model for hospital readmission risk were included. We defined the scope of the review and accordingly built a search query to select the candidate papers. This query string was used as input for the chosen search engines, namely PubMed and Google Scholar. For each study, we recorded the population, feature selection method, classification algorithm, sample size, readmission threshold, readmission rate and predictive performance of the model. We identified 77 studies that met the inclusion criteria, out of 265 citations. In 68\% of the studies (n = 52) logistic regression or other regression techniques were utilized as the main method. Ten (13\%) studies used survival analysis for model construction, while 14 (18\%) used machine learning techniques for classification, of which decision tree-based methods and SVM were the most utilized algorithms. Among these, only four studies reported the use of any class imbalance addressing technique, of which resampling is the most frequent (75\%). The performance of the models varied significantly among studies, with Area Under the ROC Curve (AUC) values in the ranges between 0.54 and 0.92. Logistic regression and survival analysis have been traditionally the most widely used techniques for model building. Nevertheless, machine learning techniques are becoming increasingly popular in recent years. Recent comparative studies suggest that machine learning techniques can improve prediction ability over traditional statistical approaches. Regardless, the lack of an appropriate benchmark dataset of hospital readmissions makes a comparison of models' performance across different studies difficult.},
  citation-subset = {IM},
  completed       = {2019-01-07},
  country         = {Ireland},
  issn-linking    = {0169-2607},
  journal         = {Computer Methods and Programs in Biomedicine},
  keywords        = {Algorithms; Area Under Curve; Data Interpretation, Statistical; Hospital Mortality; Humans; Logistic Models; Machine Learning; Models, Statistical; Patient Readmission, statistics & numerical data; Risk Factors},
  month           = oct,
  nlm-id          = {8506513},
  owner           = {NLM},
  pii             = {S0169-2607(17)31399-8},
  pmid            = {30195431},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2019-01-07},
  year            = {2018},
}

@Article{Aubert2017,
  author          = {Aubert, Carole E and Schnipper, Jeffrey L and Williams, Mark V and Robinson, Edmondo J and Zimlichman, Eyal and Vasilevskis, Eduard E and Kripalani, Sunil and Metlay, Joshua P and Wallington, Tamara and Fletcher, Grant S and Auerbach, Andrew D and Aujesky, Drahomir and D Donzé, Jacques},
  title           = {Simplification of the HOSPITAL score for predicting 30-day readmissions.},
  volume          = {26},
  issue           = {10},
  pages           = {799--805},
  issn            = {2044-5423},
  doi             = {10.1136/bmjqs-2016-006239},
  abstract        = {The HOSPITAL score has been widely validated and accurately identifies high-risk patients who may mostly benefit from transition care interventions. Although this score is easy to use, it has the potential to be simplified without impacting its performance. We aimed to validate a simplified version of the HOSPITAL score for predicting patients likely to be readmitted. Retrospective study in 9 large hospitals across 4 countries, from January through December 2011. We included all consecutively discharged medical patients. We excluded patients who died before discharge or were transferred to another acute care facility. The primary outcome was any 30-day potentially avoidable readmission. We simplified the score as follows: (1) 'discharge from an oncology division' was replaced by 'cancer diagnosis or discharge from an oncology division'; (2) 'any procedure' was left out; (3) patients were categorised into two risk groups (unlikely and likely to be readmitted). The performance of the simplified HOSPITAL score was evaluated according to its overall accuracy, its discriminatory power and its calibration. Thirty-day potentially avoidable readmission rate was 9.7\% (n=11 307/117 065 patients discharged). Median of the simplified HOSPITAL score was 3 points (IQR 2-5). Overall accuracy was very good with a Brier score of 0.08 and discriminatory power remained good with a C-statistic of 0.69 (95\% CI 0.68 to 0.69). The calibration was excellent when comparing the expected with the observed risk in the two risk categories. The simplified HOSPITAL score has good performance for predicting 30-day readmission. Prognostic accuracy was similar to the original version, while its use is even easier. This simplified score may provide a good alternative to the original score depending on the setting.},
  chemicals       = {Hemoglobins, Sodium},
  citation-subset = {H},
  completed       = {2018-06-04},
  country         = {England},
  issn-linking    = {2044-5415},
  journal         = {BMJ Quality \& Safety},
  keywords        = {Adult; Aged; Aged, 80 and over; Female; Hemoglobins; Humans; International Classification of Diseases; Male; Middle Aged; Neoplasms, epidemiology; Patient Admission, statistics & numerical data; Patient Readmission, statistics & numerical data; Predictive Value of Tests; Retrospective Studies; Risk Factors; Sodium, blood; Adverse events, epidemiology and detection; Hospital medicine; Risk management; Transitions in care},
  month           = oct,
  nlm-id          = {101546984},
  owner           = {NLM},
  pii             = {bmjqs-2016-006239},
  pmid            = {28416652},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2018-06-04},
  year            = {2017},
}

@Article{Auerbach2016,
  author   = {Auerbach, Andrew D. and Kripalani, Sunil and Vasilevskis, Eduard E. and Sehgal, Neil and Lindenauer, Peter K. and Metlay, Joshua P. and Fletcher, Grant and Ruhnke, Gregory W. and Flanders, Scott A. and Kim, Christopher and Williams, Mark V. and Thomas, Larissa and Giang, Vernon and Herzig, Shoshana J. and Patel, Kanan and Boscardin, W. John and Robinson, Edmondo J. and Schnipper, Jeffrey L.},
  title    = {{Preventability and causes of readmissions in a national cohort of general medicine patients}},
  volume   = {176},
  number   = {4},
  pages    = {484-493},
  issn     = {2168-6106},
  doi      = {10.1001/jamainternmed.2015.7863},
  eprint   = {https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/2498846/ioi150109.pdf},
  url      = {https://doi.org/10.1001/jamainternmed.2015.7863},
  abstract = {{Readmission penalties have catalyzed efforts to improve care transitions, but few programs have incorporated viewpoints of patients and health care professionals to determine readmission preventability or to prioritize opportunities for care improvement.To determine preventability of readmissions and to use these estimates to prioritize areas for improvement.An observational study was conducted of 1000 general medicine patients readmitted within 30 days of discharge to 12 US academic medical centers between April 1, 2012, and March 31, 2013. We surveyed patients and physicians, reviewed documentation, and performed 2-physician case review to determine preventability of and factors contributing to readmission. We used bivariable statistics to compare preventable and nonpreventable readmissions, multivariable models to identify factors associated with potential preventability, and baseline risk factor prevalence and adjusted odds ratios (aORs) to determine the proportion of readmissions affected by individual risk factors.Likelihood that a readmission could have been prevented.The study cohort comprised 1000 patients (median age was 55 years). Of these, 269 (26.9\%) were considered potentially preventable. In multivariable models, factors most strongly associated with potential preventability included emergency department decision making regarding the readmission (aOR, 9.13; 95\% CI, 5.23-15.95), failure to relay important information to outpatient health care professionals (aOR, 4.19; 95\% CI, 2.17-8.09), discharge of patients too soon (aOR, 3.88; 95\% CI, 2.44-6.17), and lack of discussions about care goals among patients with serious illnesses (aOR, 3.84; 95\% CI, 1.39-10.64). The most common factors associated with potentially preventable readmissions included emergency department decision making (affecting 9.0\%; 95\% CI, 7.1\%-10.3\%), inability to keep appointments after discharge (affecting 8.3\%; 95\% CI, 4.1\%-12.0\%), premature discharge from the hospital (affecting 8.7\%; 95\% CI, 5.8\%-11.3\%), and patient lack of awareness of whom to contact after discharge (affecting 6.2\%; 95\% CI, 3.5\%-8.7\%).Approximately one-quarter of readmissions are potentially preventable when assessed using multiple perspectives. High-priority areas for improvement efforts include improved communication among health care teams and between health care professionals and patients, greater attention to patients’ readiness for discharge, enhanced disease monitoring, and better support for patient self-management.}},
  journal  = {JAMA Internal Medicine},
  month    = {04},
  year     = {2016},
}

@Article{Burke2017,
  author   = {Burke, Robert E. and Schnipper, Jeffrey L. and Williams, Mark V. and Robinson, Edmondo J. and Vasilevskis, Eduard E. and Kripalani, Sunil and Metlay, Joshua P. and Fletcher, Grant S. and Auerbach, Andrew D. and Donzé, Jacques D.},
  title    = {The HOSPITAL score predicts potentially preventable 30-day readmissions in conditions targeted by the Hospital Readmissions Reduction Program},
  volume   = {55},
  number   = {3},
  issn     = {0025-7079},
  url      = {https://journals.lww.com/lww-medicalcare/Fulltext/2017/03000/The_HOSPITAL_Score_Predicts_Potentially.12.aspx},
  abstract = {Background/Objectives: New tools to accurately identify potentially preventable 30-day readmissions are needed. The HOSPITAL score has been internationally validated for medical inpatients, but its performance in select conditions targeted by the Hospital Readmission Reduction Program (HRRP) is unknown. Design: Retrospective cohort study. Setting: Six geographically diverse medical centers. Participants/Exposures: All consecutive adult medical patients discharged alive in 2011 with 1 of the 4 medical conditions targeted by the HRRP (acute myocardial infarction, chronic obstructive pulmonary disease, pneumonia, and heart failure) were included. Potentially preventable 30-day readmissions were identified using the SQLape algorithm. The HOSPITAL score was calculated for all patients. Measurements: A multivariable logistic regression model accounting for hospital effects was used to evaluate the accuracy (Brier score), discrimination (c-statistic), and calibration (Pearson goodness-of-fit) of the HOSPITAL score for each 4 medical conditions. Results: Among the 9181 patients included, the overall 30-day potentially preventable readmission rate was 13.6\%. Across all 4 diagnoses, the HOSPITAL score had very good accuracy (Brier score of 0.11), good discrimination (c-statistic of 0.68), and excellent calibration (Hosmer-Lemeshow goodness-of-fit test, P=0.77). Within each diagnosis, performance was similar. In sensitivity analyses, performance was similar for all readmissions (not just potentially preventable) and when restricted to patients age 65 and above. Conclusions: The HOSPITAL score identifies a high-risk cohort for potentially preventable readmissions in a variety of practice settings, including conditions targeted by the HRRP. It may be a valuable tool when included in interventions to reduce readmissions within or across these conditions.},
  journal  = {Medical Care},
  keywords = {patient readmission, score, risk factors, transition of care},
  refid    = {00005650-201703000-00012},
  year     = {2017},
}
@Article{Collins2015,
  author   = {Collins, Gary S. and Reitsma, Johannes B. and Altman, Douglas G. and Moons, Karel G.M.},
  title    = {{Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD): The TRIPOD Statement}},
  volume   = {162},
  number   = {1},
  pages    = {55-63},
  issn     = {0003-4819},
  doi      = {10.7326/M14-0697},
  eprint   = {https://annals.org/acp/content\_public/journal/aim/931895/0000605-201501060-00009.pdf},
  url      = {https://doi.org/10.7326/M14-0697},
  abstract = {{This article has been corrected. The original version (PDF) is appended to this article as a Supplement.Prediction models are developed to aid health care providers in estimating the probability or risk that a specific disease or condition is present (diagnostic models) or that a specific event will occur in the future (prognostic models), to inform their decision making. However, the overwhelming evidence shows that the quality of reporting of prediction model studies is poor. Only with full and clear reporting of information on all aspects of a prediction model can risk of bias and potential usefulness of prediction models be adequately assessed. The Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) Initiative developed a set of recommendations for the reporting of studies developing, validating, or updating a prediction model, whether for diagnostic or prognostic purposes. This article describes how the TRIPOD Statement was developed. An extensive list of items based on a review of the literature was created, which was reduced after a Web-based survey and revised during a 3-day meeting in June 2011 with methodologists, health care professionals, and journal editors. The list was refined during several meetings of the steering group and in e-mail discussions with the wider group of TRIPOD contributors. The resulting TRIPOD Statement is a checklist of 22 items, deemed essential for transparent reporting of a prediction model study. The TRIPOD Statement aims to improve the transparency of the reporting of a prediction model study regardless of the study methods used. The TRIPOD Statement is best used in conjunction with the TRIPOD explanation and elaboration document. To aid the editorial process and readers of prediction model studies, it is recommended that authors include a completed checklist in their submission (also available at www.tripod-statement.org).}},
  journal  = {Annals of Internal Medicine},
  month    = {01},
  year     = {2015},
}

@Article{Donze2013,
  author   = {Donzé, Jacques and Aujesky, Drahomir and Williams, Deborah and Schnipper, Jeffrey L.},
  title    = {{Potentially avoidable 30-day hospital readmissions in medical patients: derivation and validation of a prediction model}},
  volume   = {173},
  number   = {8},
  pages    = {632-638},
  issn     = {2168-6106},
  doi      = {10.1001/jamainternmed.2013.3023},
  eprint   = {https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/1672282/ioi120113\_632\_638.pdf},
  url      = {https://doi.org/10.1001/jamainternmed.2013.3023},
  abstract = {{Because effective interventions to reduce hospital readmissions are often expensive to implement, a score to predict potentially avoidable readmissions may help target the patients most likely to benefit.To derive and internally validate a prediction model for potentially avoidable 30-day hospital readmissions in medical patients using administrative and clinical data readily available prior to discharge.Retrospective cohort study.Academic medical center in Boston, Massachusetts.All patient discharges from any medical services between July 1, 2009, and June 30, 2010.Potentially avoidable 30-day readmissions to 3 hospitals of the Partners HealthCare network were identified using a validated computerized algorithm based on administrative data (SQLape). A simple score was developed using multivariable logistic regression, with two-thirds of the sample randomly selected as the derivation cohort and one-third as the validation cohort.Among 10 731 eligible discharges, 2398 discharges (22.3\%) were followed by a 30-day readmission, of which 879 (8.5\% of all discharges) were identified as potentially avoidable. The prediction score identified 7 independent factors, referred to as the HOSPITAL score: h emoglobin at discharge, discharge from an o ncology service, s odium level at discharge, p rocedure during the index admission, i ndex t ype of admission, number of a dmissions during the last 12 months, and l ength of stay. In the validation set, 26.7\% of the patients were classified as high risk, with an estimated potentially avoidable readmission risk of 18.0\% (observed, 18.2\%). The HOSPITAL score had fair discriminatory power (C statistic, 0.71) and had good calibration.This simple prediction model identifies before discharge the risk of potentially avoidable 30-day readmission in medical patients. This score has potential to easily identify patients who may need more intensive transitional care interventions.}},
  journal  = {JAMA Internal Medicine},
  month    = {04},
  year     = {2013},
}

@Article{Ephrem2013,
  author          = {Ephrem, Georges},
  title           = {Red blood cell distribution width is a predictor of readmission in cardiac patients.},
  volume          = {36},
  issue           = {5},
  pages           = {293--299},
  issn            = {1932-8737},
  doi             = {10.1002/clc.22116},
  abstract        = {Three-quarters of rehospitalizations ($44 billion yearly estimated cost) may be avoidable. A screening tool for the detection of potential readmission may facilitate more efficient case management. An elevated red blood cell distribution width (RDW) is an independent predictor of hospital readmission in patients with unstable angina (UA) or non-ST-elevation myocardial infarction (NSTEMI). The study is a retrospective observational cohort analysis of adults admitted in 2007 with UA or NSTEMI. Data were gathered by review of inpatient medical records. The rate of 30-day nonelective readmission and time to nonelective readmission were recorded until November 1, 2011, and compared by RDW group using the 95th percentile (16.3\%) as a cutoff. The median follow-up time of the 503 subjects (average age, 65 ± 13 years; 56\% male) was 3.8 years (interquartile range: 0.3-4.3 years). Those readmitted within 30 days were older, had more comorbidities and higher RDW and creatinine levels, and were more likely to have had an intervention. At 3.8 years of follow-up, subjects with high RDW (>16.3\%) were more likely to be readmitted compared to those with normal RDW (≤16.3\%) (72.28\% vs 59.95\%, P = 0.003). In multivariable analyses, high RDW was a statistically significant predictor of readmission in general (hazard ratio: 1.35 (95\% confidence interval [CI]:1.02-1.79), P = 0.033) but not of 30-day rehospitalization (odds ratio: 1.34 (95\% CI: 0.78-2.31), P = 0.292). Its area under the receiver operating characteristic curve was 0.54 (sensitivity 23\% and specificity 85\%). An elevated RDW is an independent predictor of hospital readmission in patients with UA or NSTEMI.},
  citation-subset = {IM},
  completed       = {2013-12-16},
  country         = {United States},
  issn-linking    = {0160-9289},
  journal         = {Clinical cardiology},
  keywords        = {Aged; Angina, Unstable, blood, diagnosis, therapy; Area Under Curve; Chi-Square Distribution; Erythrocyte Indices; Female; Humans; Logistic Models; Male; Middle Aged; Multivariate Analysis; Myocardial Infarction, blood, diagnosis, therapy; Odds Ratio; Patient Readmission; Predictive Value of Tests; Prognosis; Proportional Hazards Models; ROC Curve; Retrospective Studies; Risk Factors; Time Factors},
  month           = may,
  nlm-id          = {7903272},
  owner           = {NLM},
  pmid            = {23553899},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2013-05-14},
  year            = {2013},
}

@Article{Garrison2017,
  author   = {Garrison, Gregory M. and Robelia, Paul M. and Pecina, Jennifer L. and Dawson, Nancy L.},
  title    = {Comparing performance of 30-day readmission risk classifiers among hospitalized primary care patients},
  volume   = {23},
  number   = {3},
  pages    = {524-529},
  doi      = {10.1111/jep.12656},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/jep.12656},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jep.12656},
  abstract = {Abstract Rationale, aims and objectives Hospital readmission within 30 days of discharge occurs in almost 20\% of US Medicare patients and may be a marker of poor quality inpatient care, ineffective hospital to home transitions, or disease severity. Within a patient centered medical home, care transition interventions may only be practical from cost and staffing perspectives if targeted at patients with the greatest risk of readmission. Various scoring algorithms attempt to predict patients at risk for 30-day readmission, but head-to-head comparison of performance is lacking. Compare published scoring algorithms which use generally available electronic medical record data on the same set of hospitalized primary care patients. Methods The LACE index, the LACE+ index, the HOSPITAL score, and the readmission risk score were computed on a consecutive cohort of 26,278 hospital admissions. Classifier performance was assessed by plotting receiver operating characteristic curves comparing the computed score with the actual outcome of death or readmission within 30 days. Statistical significance of differences in performance was assessed using bootstrapping techniques. Results Correct readmission classification on this cohort was moderate with the following c-statistics: Readmission risk score 0.666; LACE 0.680; LACE+ 0.662; and HOSPITAL 0.675. There was no statistically significant difference in performance between classifiers. Conclusions Logistic regression based classifiers yield only moderate performance when utilized to predict 30-day readmissions. The task is difficult due to the variety of underlying causes for readmission, nonlinearity, and the arbitrary time period of concern. More sophisticated classification techniques may be necessary to increase performance and allow patient centered medical homes to effectively focus efforts to reduce readmissions.},
  journal  = {Journal of Evaluation in Clinical Practice},
  keywords = {decision support techniques, hospital medicine, patient readmission, primary health care},
  year     = {2017},
}

@Article{Golas2018,
author                 = {Golas, Sara Bersche and Shibahara, Takuma and Agboola, Stephen and Otaki, Hiroko and Sato, Jumpei and Nakae, Tatsuya and Hisamitsu, Toru and Kojima, Go and Felsted, Jennifer and Kakarmath, Sujay and Kvedar, Joseph and Jethwani, Kamal},
title                  = {A machine learning model to predict the risk of 30-day readmissions in patients with heart failure: a retrospective analysis of electronic medical records data.},
language               = {eng},
volume                 = {18},
issue                  = {1},
pages                  = {44},
abstract               = {BACKGROUND: Heart failure is one of the leading causes of hospitalization in the United States. Advances in big data solutions allow for storage, management, and mining of large volumes of structured and semi-structured data, such as complex healthcare data. Applying these advances to complex healthcare data has led to the development of risk prediction models to help identify patients who would benefit most from disease management programs in an effort to reduce readmissions and healthcare cost, but the results of these efforts have been varied. The primary aim of this study was to develop a 30-day readmission risk prediction model for heart failure patients discharged from a hospital admission. METHODS: We used longitudinal electronic medical record data of heart failure patients admitted within a large healthcare system. Feature vectors included structured demographic, utilization, and clinical data, as well as selected extracts of un-structured data from clinician-authored notes. The risk prediction model was developed using deep unified networks (DUNs), a new mesh-like network structure of deep learning designed to avoid over-fitting. The model was validated with 10-fold cross-validation and results compared to models based on logistic regression, gradient boosting, and maxout networks. Overall model performance was assessed using concordance statistic. We also selected a discrimination threshold based on maximum projected cost saving to the Partners Healthcare system. RESULTS: Data from 11,510 patients with 27,334 admissions and 6369 30-day readmissions were used to train the model. After data processing, the final model included 3512 variables. The DUNs model had the best performance after 10-fold cross-validation. AUCs for prediction models were 0.664 +/- 0.015, 0.650 +/- 0.011, 0.695 +/- 0.016 and 0.705 +/- 0.015 for logistic regression, gradient boosting, maxout networks, and DUNs respectively. The DUNs model had an accuracy of 76.4\% at the classification threshold that corresponded with maximum cost saving to the hospital. CONCLUSIONS: Deep learning techniques performed better than other traditional techniques in developing this EMR-based prediction model for 30-day readmissions in heart failure patients. Such models can be used to identify heart failure patients with impending hospitalization, enabling care teams to target interventions at their most high-risk patients and improving overall clinical outcomes.},
address                = {England},
article-doi            = {10.1186/s12911-018-0620-z},
article-pii            = {10.1186/s12911-018-0620-z},
completed              = {20190319},
electronic-issn        = {1472-6947},
electronic-publication = {20180622},
history                = {2019/03/20 06:00 [medline]},
journal                = {BMC medical informatics and decision making},
keywords               = {Aged, Aged, 80 and over, *Deep Learning, Electronic Health Records/*statistics & numerical data, Female, Heart Failure/diagnosis/*therapy, Humans, Male, Middle Aged, *Models, Theoretical, Patient Readmission/*statistics & numerical data, Prognosis, Retrospective Studies, *Deep learning, *Deep unified networks, *Heart failure, *Machine learning, *Readmission reduction, *Value-based care},
linking-issn           = {1472-6947},
location-id            = {10.1186/s12911-018-0620-z [doi]},
month                  = {Jun},
nlm-unique-id          = {101088682},
owner                  = {NLM},
publication-status     = {epublish},
revised                = {20190319},
source                 = {BMC Med Inform Decis Mak. 2018 Jun 22;18(1):44. doi: 10.1186/s12911-018-0620-z.},
status                 = {MEDLINE},
subset                 = {IM},
termowner              = {NOTNLM},
title-abbreviation     = {BMC Med Inform Decis Mak},
year                   = {2018},
}

@Article{Leppin2014,
  author   = {Leppin, Aaron L. and Gionfriddo, Michael R. and Kessler, Maya and Brito, Juan Pablo and Mair, Frances S. and Gallacher, Katie and Wang, Zhen and Erwin, Patricia J. and Sylvester, Tanya and Boehmer, Kasey and Ting, Henry H. and Murad, M. Hassan and Shippee, Nathan D. and Montori, Victor M.},
  title    = {{Preventing 30-Day Hospital Readmissions: A Systematic Review and Meta-analysis of Randomized Trials}},
  volume   = {174},
  number   = {7},
  pages    = {1095-1107},
  issn     = {2168-6106},
  doi      = {10.1001/jamainternmed.2014.1608},
  eprint   = {https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/1868538/ioi140038.pdf},
  url      = {https://doi.org/10.1001/jamainternmed.2014.1608},
  abstract = {{Reducing early (\\&lt;30 days) hospital readmissions is a policy priority aimed at improving health care quality. The cumulative complexity model conceptualizes patient context. It predicts that highly supportive discharge interventions will enhance patient capacity to enact burdensome self-care and avoid readmissions.To synthesize the evidence of the efficacy of interventions to reduce early hospital readmissions and identify intervention features—including their impact on treatment burden and on patients’ capacity to enact postdischarge self-care—that might explain their varying effects.We searched PubMed, Ovid MEDLINE, Ovid EMBASE, EBSCO CINAHL, and Scopus (1990 until April 1, 2013), contacted experts, and reviewed bibliographies.Randomized trials that assessed the effect of interventions on all-cause or unplanned readmissions within 30 days of discharge in adult patients hospitalized for a medical or surgical cause for more than 24 hours and discharged to home.Reviewer pairs extracted trial characteristics and used an activity-based coding strategy to characterize the interventions; fidelity was confirmed with authors. Blinded to trial outcomes, reviewers noted the extent to which interventions placed additional work on patients after discharge or supported their capacity for self-care in accordance with the cumulative complexity model.Relative risk of all-cause or unplanned readmission with or without out-of-hospital deaths at 30 days postdischarge.In 42 trials, the tested interventions prevented early readmissions (pooled random-effects relative risk, 0.82 [95\% CI, 0.73-0.91]; P \\&lt; .001; I2 = 31\%), a finding that was consistent across patient subgroups. Trials published before 2002 reported interventions that were 1.6 times more effective than those tested later (interaction P = .01). In exploratory subgroup analyses, interventions with many components (interaction P = .001), involving more individuals in care delivery (interaction P = .05), and supporting patient capacity for self-care (interaction P = .04) were 1.4, 1.3, and 1.3 times more effective than other interventions, respectively. A post hoc regression model showed incremental value in providing comprehensive, postdischarge support to patients and caregivers.Tested interventions are effective at reducing readmissions, but more effective interventions are complex and support patient capacity for self-care. Interventions tested more recently are less effective.}},
  journal  = {JAMA Internal Medicine},
  month    = {07},
  year     = {2014},
}

@Article{Rajkomar2018,
  author   = {Rajkomar, Alvin and Oren, Eyal and Chen, Kai and Dai, Andrew M. and Hajaj, Nissan and Hardt, Michaela and Liu, Peter J. and Liu, Xiaobing and Marcus, Jake and Sun, Mimi and Sundberg, Patrik and Yee, Hector and Zhang, Kun and Zhang, Yi and Flores, Gerardo and Duggan, Gavin E. and Irvine, Jamie and Le, Quoc and Litsch, Kurt and Mossin, Alexander and Tansuwan, Justin and Wang, De and Wexler, James and Wilson, Jimbo and Ludwig, Dana and Volchenboum, Samuel L. and Chou, Katherine and Pearson, Michael and Madabushi, Srinivasan and Shah, Nigam H. and Butte, Atul J. and Howell, Michael D. and Cui, Claire and Corrado, Greg S. and Dean, Jeffrey},
  title    = {Scalable and accurate deep learning with electronic health records},
  volume   = {1},
  number   = {1},
  pages    = {18},
  issn     = {2398-6352},
  url      = {https://doi.org/10.1038/s41746-018-0029-1},
  abstract = {Predictive modeling with electronic health record (EHR) data is anticipated to drive personalized medicine and improve healthcare quality. Constructing predictive statistical models typically requires extraction of curated predictor variables from normalized EHR data, a labor-intensive process that discards the vast majority of information in each patient’s record. We propose a representation of patients’ entire raw EHR records based on the Fast Healthcare Interoperability Resources (FHIR) format. We demonstrate that deep learning methods using this representation are capable of accurately predicting multiple medical events from multiple centers without site-specific data harmonization. We validated our approach using de-identified EHR data from two US academic medical centers with 216,221 adult patients hospitalized for at least 24 h. In the sequential format we propose, this volume of EHR data unrolled into a total of 46,864,534,945 data points, including clinical notes. Deep learning models achieved high accuracy for tasks such as predicting: in-hospital mortality (area under the receiver operator curve [AUROC] across sites 0.93-0.94), 30-day unplanned readmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and all of a patient’s final discharge diagnoses (frequency-weighted AUROC 0.90). These models outperformed traditional, clinically-used predictive models in all cases. We believe that this approach can be used to create accurate and scalable predictions for a variety of clinical scenarios. In a case study of a particular prediction, we demonstrate that neural networks can be used to identify relevant information from the patient’s chart.},
  journal  = {npj Digital Medicine},
  refid    = {Rajkomar2018},
  year     = {2018},
}

@Article{Saunders2015,
  author          = {Saunders, Neil David and Nichols, Shawnn D and Antiporda, Michael Alfredo and Johnson, Kristen and Walker, Kerri and Nilsson, Rhonda and Graham, Lisa and Old, Matt and Klisovic, Rebecca B and Penza, Sam and Schmidt, Carl R},
  title           = {Examination of unplanned 30-day readmissions to a comprehensive cancer hospital.},
  volume          = {11},
  issue           = {2},
  pages           = {e177--e181},
  issn            = {1935-469X},
  doi             = {10.1200/JOP.2014.001546},
  abstract        = {The Centers for Medicare and Medicaid Services (CMS), under the Hospitals Readmissions Reductions Program, may withhold regular reimbursements for excessive 30-day readmissions for select diagnoses. Such penalties imply that some readmissions reflect poor clinical decision making or care during the initial hospitalization. We examined factors related to potentially preventable readmissions in CMS patients at a tertiary cancer hospital. The medical records of all CMS patients with unplanned readmissions within 30 days of index admission were reviewed over 6 months (October 15, 2011-April 15, 2012). Each readmission was classified as not preventable or potentially preventable. Factors associated with potentially preventable readmissions were sought. Of 2,531 inpatient admissions in CMS patients over 6 months, 185 patients experienced at least one readmission for 282 total readmissions (11\%). Median time to readmission was 9 days (range, 0 to 30 days). The most common causes for first readmission were new diagnoses not present at first admission (n = 43, 23\%), new or worsening symptoms due to cancer progression (n = 40, 21\%) and complications of procedures (n = 25, 13\%). There were 38 (21\%) initial readmissions classified as potentially preventable. Use of total parenteral nutrition at the time of discharge was associated with potentially preventable readmission (P = .028). Most unplanned readmissions to a tertiary cancer hospital are related to progression of disease, new diagnoses, and procedure complications. Minimizing readmissions in complex cancer patients is challenging. Larger multi-institutional datasets are needed to determine a reasonable standard for expected readmission rates.},
  citation-subset = {IM},
  completed       = {2016-02-08},
  country         = {United States},
  issn-linking    = {1554-7477},
  journal         = {Journal of Oncology Practice},
  keywords        = {Adult; Aged; Aged, 80 and over; Cancer Care Facilities, statistics & numerical data; Centers for Medicare and Medicaid Services (U.S.); Female; Humans; Inpatients; Male; Middle Aged; Patient Readmission, statistics & numerical data; United States; Young Adult},
  month           = mar,
  nlm-id          = {101261852},
  owner           = {NLM},
  pii             = {JOP.2014.001546},
  pmid            = {25585616},
  pubmodel        = {Print-Electronic},
  pubstatus       = {ppublish},
  revised         = {2016-10-20},
  year            = {2015},
}

@Article{Smith2018,
  author       = {Smith, Lauren N and Makam, Anil N and Darden, Douglas and Mayo, Helen and Das, Sandeep R and Halm, Ethan A and Nguyen, Oanh Kieu},
  title        = {Acute Myocardial Infarction Readmission Risk Prediction Models: A Systematic Review of Model Performance.},
  volume       = {11},
  issue        = {1},
  pages        = {e003885},
  issn         = {1941-7705},
  doi          = {10.1161/CIRCOUTCOMES.117.003885},
  abstract     = {Hospitals are subject to federal financial penalties for excessive 30-day hospital readmissions for acute myocardial infarction (AMI). Prospectively identifying patients hospitalized with AMI at high risk for readmission could help prevent 30-day readmissions by enabling targeted interventions. However, the performance of AMI-specific readmission risk prediction models is unknown. We systematically searched the published literature through March 2017 for studies of risk prediction models for 30-day hospital readmission among adults with AMI. We identified 11 studies of 18 unique risk prediction models across diverse settings primarily in the United States, of which 16 models were specific to AMI. The median overall observed all-cause 30-day readmission rate across studies was 16.3\% (range, 10.6\%-21.0\%). Six models were based on administrative data; 4 on electronic health record data; 3 on clinical hospital data; and 5 on cardiac registry data. Models included 7 to 37 predictors, of which demographics, comorbidities, and utilization metrics were the most frequently included domains. Most models, including the Centers for Medicare and Medicaid Services AMI administrative model, had modest discrimination (median C statistic, 0.65; range, 0.53-0.79). Of the 16 reported AMI-specific models, only 8 models were assessed in a validation cohort, limiting generalizability. Observed risk-stratified readmission rates ranged from 3.0\% among the lowest-risk individuals to 43.0\% among the highest-risk individuals, suggesting good risk stratification across all models. Current AMI-specific readmission risk prediction models have modest predictive ability and uncertain generalizability given methodological limitations. No existing models provide actionable information in real time to enable early identification and risk-stratification of patients with AMI before hospital discharge, a functionality needed to optimize the potential effectiveness of readmission reduction interventions.},
  country      = {United States},
  issn-linking = {1941-7713},
  journal      = {Circulation. Cardiovascular quality and outcomes},
  keywords     = {Medicaid; Medicare; myocardial infarction; patient readmission; risk},
  mid          = {NIHMS927219},
  month        = jan,
  nlm-id       = {101489148},
  owner        = {NLM},
  pii          = {CIRCOUTCOMES.117.003885},
  pmc          = {PMC5858710},
  pmid         = {29321135},
  pubmodel     = {Print},
  pubstatus    = {ppublish},
  revised      = {2019-01-07},
  year         = {2018},
}

@Article{Steyerberg2010,
  author          = {Steyerberg, Ewout W and Vickers, Andrew J and Cook, Nancy R and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J and Kattan, Michael W},
  title           = {Assessing the performance of prediction models: a framework for traditional and novel measures.},
  volume          = {21},
  issue           = {1},
  pages           = {128--138},
  issn            = {1531-5487},
  doi             = {10.1097/EDE.0b013e3181c30fb2},
  abstract        = {The performance of prediction models can be assessed using a variety of methods and metrics. Traditional measures for binary and survival outcomes include the Brier score to indicate overall model performance, the concordance (or c) statistic for discriminative ability (or area under the receiver operating characteristic [ROC] curve), and goodness-of-fit statistics for calibration.Several new measures have recently been proposed that can be seen as refinements of discrimination measures, including variants of the c statistic for survival, reclassification tables, net reclassification improvement (NRI), and integrated discrimination improvement (IDI). Moreover, decision-analytic measures have been proposed, including decision curves to plot the net benefit achieved by making decisions based on model predictions.We aimed to define the role of these relatively novel approaches in the evaluation of the performance of prediction models. For illustration, we present a case study of predicting the presence of residual tumor versus benign tissue in patients with testicular cancer (n = 544 for model development, n = 273 for external validation).We suggest that reporting discrimination and calibration will always be important for a prediction model. Decision-analytic measures should be reported if the predictive model is to be used for clinical decisions. Other measures of performance may be warranted in specific applications, such as reclassification metrics to gain insight into the value of adding a novel predictor to an established model.},
  citation-subset = {IM},
  completed       = {2010-03-09},
  country         = {United States},
  issn-linking    = {1044-3983},
  journal         = {Epidemiology (Cambridge, Mass.)},
  keywords        = {Epidemiologic Studies; Models, Statistical; Prognosis; ROC Curve; Reproducibility of Results; Risk Assessment, methods, standards, statistics & numerical data},
  mid             = {NIHMS438237},
  month           = jan,
  nlm-id          = {9009644},
  owner           = {NLM},
  pii             = {00001648-201001000-00022},
  pmc             = {PMC3575184},
  pmid            = {20010215},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2018-11-13},
  year            = {2010},
}

@Article{Wadhera2018,
  author   = {Wadhera, Rishi K. and Joynt Maddox, Karen E. and Wasfy, Jason H. and Haneuse, Sebastien and Shen, Changyu and Yeh, Robert W.},
  title    = {Association of the Hospital Readmissions Reduction Program with heart failure, AMI, and pneumonia mortality},
  volume   = {320},
  number   = {24},
  pages    = {2542-2552},
  issn     = {0098-7484},
  doi      = {10.1001/jama.2018.19232},
  eprint   = {https://jamanetwork.com/journals/jama/articlepdf/2719307/jama\_wadhera\_2018\_oi\_180144.pdf},
  url      = {https://doi.org/10.1001/jama.2018.19232},
  abstract = {{The Hospital Readmissions Reduction Program (HRRP) has been associated with a reduction in readmission rates for heart failure (HF), acute myocardial infarction (AMI), and pneumonia. It is unclear whether the HRRP has been associated with change in patient mortality.To determine whether the HRRP was associated with a change in patient mortality.Retrospective cohort study of hospitalizations for HF, AMI, and pneumonia among Medicare fee-for-service beneficiaries aged at least 65 years across 4 periods from April 1, 2005, to March 31, 2015. Period 1 and period 2 occurred before the HRRP to establish baseline trends (April 2005-September 2007 and October 2007-March 2010). Period 3 and period 4 were after HRRP announcement (April 2010 to September 2012) and HRRP implementation (October 2012 to March 2015).Announcement and implementation of the HRRP.Inverse probability–weighted mortality within 30 days of discharge following hospitalization for HF, AMI, and pneumonia, and stratified by whether there was an associated readmission. An additional end point was mortality within 45 days of initial hospital admission for target conditions.The study cohort included 8.3 million hospitalizations for HF, AMI, and pneumonia, among which 7.9 million (mean age, 79.6 [8.7] years; 53.4\% women) were alive at discharge. There were 3.2 million hospitalizations for HF, 1.8 million for AMI, and 3.0 million for pneumonia. There were 270 517 deaths within 30 days of discharge for HF, 128 088 for AMI, and 246 154 for pneumonia. Among patients with HF, 30-day postdischarge mortality increased before the announcement of the HRRP (0.27\% increase from period 1 to period 2). Compared with this baseline trend, HRRP announcement (0.49\% increase from period 2 to period 3; difference in change, 0.22\%, P = .01) and implementation (0.52\% increase from period 3 to period 4; difference in change, 0.25\%, P = .001) were significantly associated with an increase in postdischarge mortality. Among patients with AMI, HRRP announcement was associated with a decline in postdischarge mortality (0.18\% pre-HRRP increase vs 0.08\% post-HRRP announcement decrease; difference in change, −0.26\%; P = .01) and did not significantly change after HRRP implementation. Among patients with pneumonia, postdischarge mortality was stable before HRRP (0.04\% increase from period 1 to period 2), but significantly increased after HRRP announcement (0.26\% post-HRRP announcement increase; difference in change, 0.22\%, P = .01) and implementation (0.44\% post-HPPR implementation increase; difference in change, 0.40\%, P \\&lt; .001). The overall increase in mortality among patients with HF and pneumonia was mainly related to outcomes among patients who were not readmitted but died within 30 days of discharge. For all 3 conditions, HRRP implementation was not significantly associated with an increase in mortality within 45 days of admission, relative to pre-HRRP trends.Among Medicare beneficiaries, the HRRP was significantly associated with an increase in 30-day postdischarge mortality after hospitalization for HF and pneumonia, but not for AMI. Given the study design and the lack of significant association of the HRRP with mortality within 45 days of admission, further research is needed to understand whether the increase in 30-day postdischarge mortality is a result of the policy.}},
  journal  = {JAMA},
  month    = {12},
  year     = {2018},
}

@Article{Weinreich2016,
  author          = {Weinreich, Mark and Nguyen, Oanh K and Wang, David and Mayo, Helen and Mortensen, Eric M and Halm, Ethan A and Makam, Anil N},
  title           = {Predicting the Risk of Readmission in Pneumonia. A Systematic Review of Model Performance.},
  volume          = {13},
  issue           = {9},
  pages           = {1607--1614},
  issn            = {2325-6621},
  doi             = {10.1513/AnnalsATS.201602-135SR},
  abstract        = {Predicting which patients are at highest risk for readmission after hospitalization for pneumonia could enable hospitals to proactively reallocate scarce resources to reduce 30-day readmissions. To synthesize the available literature on readmission risk prediction models for adults who are hospitalized because of pneumonia and describe their performance. We systematically searched Ovid MEDLINE, Embase, The Cochrane Library, and Cumulative Index to Nursing and Allied Health Literature databases from inception through July 2015. We included studies of adults discharged with pneumonia that developed or validated a model that predicted hospital readmission. Two independent reviewers abstracted data and assessed the risk of bias. Of 992 citations reviewed, 7 studies met inclusion criteria, which included 11 unique risk prediction models. All-cause 30-day readmission rates ranged from 11.8 to 20.8\% (median, 17.3\%). Model discrimination (C statistic) ranged from 0.59 to 0.77 (median, 0.63) with the highest-quality, best-validated model, the Centers for Medicare and Medicaid Services Pneumonia Administrative Model performing modestly (C Statistic of 0.63 in 4 separate multicenter cohorts). The best performing model (C statistic of 0.77) was a single-site study that lacked internal validation. The models had adequate calibration, with patients predicted as high risk for readmission having a higher average observed readmission rate than those predicted to be low risk. None of the studies included pneumonia illness severity scores, and only one included measures of in-hospital clinical trajectory and stability on discharge, robust predictors of readmission. We found a limited number of validated pneumonia-specific readmission models, and their predictive ability was modest. To improve predictive accuracy, future models should include measures of pneumonia illness severity, hospital complications, and stability on discharge.},
  citation-subset = {IM},
  completed       = {2018-01-11},
  country         = {United States},
  issn-linking    = {2325-6621},
  journal         = {Annals of the American Thoracic Society},
  keywords        = {Centers for Medicare and Medicaid Services (U.S.); Humans; Models, Statistical; Patient Readmission, statistics & numerical data, trends; Pneumonia, therapy; Prognosis; Risk Assessment; Time Factors; United States; model; patient readmission; pneumonia; prediction; risk},
  month           = sep,
  nlm-id          = {101600811},
  owner           = {NLM},
  pmc             = {PMC5059500},
  pmid            = {27299853},
  pubmodel        = {Print},
  pubstatus       = {ppublish},
  revised         = {2018-12-02},
  year            = {2016},
}

@Article{Yu2015,
author                 = {Yu, Shipeng and Farooq, Faisal and van Esbroeck, Alexander and Fung, Glenn and Anand, Vikram and Krishnapuram, Balaji},
title                  = {Predicting readmission risk with institution-specific prediction models.},
language               = {eng},
volume                 = {65},
issue                  = {2},
pages                  = {89-96},
abstract               = {OBJECTIVE: The ability to predict patient readmission risk is extremely valuable for hospitals, especially under the Hospital Readmission Reduction Program of the Center for Medicare and Medicaid Services which went into effect starting October 1, 2012. There is a plethora of work in the literature that deals with developing readmission risk prediction models, but most of them do not have sufficient prediction accuracy to be deployed in a clinical setting, partly because different hospitals may have different characteristics in their patient populations. METHODS AND MATERIALS: We propose a generic framework for institution-specific readmission risk prediction, which takes patient data from a single institution and produces a statistical risk prediction model optimized for that particular institution and, optionally, for a specific condition. This provides great flexibility in model building, and is also able to provide institution-specific insights in its readmitted patient population. We have experimented with classification methods such as support vector machines, and prognosis methods such as the Cox regression. We compared our methods with industry-standard methods such as the LACE model, and showed the proposed framework is not only more flexible but also more effective. RESULTS: We applied our framework to patient data from three hospitals, and obtained some initial results for heart failure (HF), acute myocardial infarction (AMI), pneumonia (PN) patients as well as patients with all conditions. On Hospital 2, the LACE model yielded AUC 0.57, 0.56, 0.53 and 0.55 for AMI, HF, PN and All Cause readmission prediction, respectively, while the proposed model yielded 0.66, 0.65, 0.63, 0.74 for the corresponding conditions, all significantly better than the LACE counterpart. The proposed models that leverage all features at discharge time is more accurate than the models that only leverage features at admission time (0.66 vs. 0.61 for AMI, 0.65 vs. 0.61 for HF, 0.63 vs. 0.56 for PN, 0.74 vs. 0.60 for All Cause). Furthermore, the proposed admission-time models already outperform the performance of LACE, which is a discharge-time model (0.61 vs. 0.57 for AMI, 0.61 vs. 0.56 for HF, 0.56 vs. 0.53 for PN, 0.60 vs. 0.55 for All Cause). Similar conclusions can be drawn from other hospitals as well. The same performance comparison also holds for precision and recall at top-decile predictions. Most of the performance improvements are statistically significant. CONCLUSIONS: The institution-specific readmission risk prediction framework is more flexible and more effective than the one-size-fit-all models like the LACE, sometimes twice and three-time more effective. The admission-time models are able to give early warning signs compared to the discharge-time models, and may be able to help hospital staff intervene early while the patient is still in the hospital.},
address                = {Netherlands},
article-doi            = {10.1016/j.artmed.2015.08.005},
article-pii            = {S0933-3657(15)00094-9},
completed              = {20160718},
electronic-issn        = {1873-2860},
electronic-publication = {20150822},
history                = {2016/07/19 06:00 [medline]},
journal                = {Artificial intelligence in medicine},
keywords               = {Humans, *Models, Theoretical, *Patient Readmission, Proportional Hazards Models, Risk Assessment, Support Vector Machine, Predictive modeling, Readmission risk prediction},
linking-issn           = {0933-3657},
location-id            = {S0933-3657(15)00094-9 [pii]},
month                  = {Oct},
nlm-unique-id          = {8915031},
owner                  = {NLM},
publication-status     = {ppublish},
revised                = {20151013},
source                 = {Artif Intell Med. 2015 Oct;65(2):89-96. doi: 10.1016/j.artmed.2015.08.005. Epub 2015 Aug 22.},
status                 = {MEDLINE},
subset                 = {IM},
termowner              = {NOTNLM},
title-abbreviation     = {Artif Intell Med},
year                   = {2015},
}

@misc{acs,
  author    = {{U.S.~Census Bureau}},
  title     = {American Community Survey 5-Year Estimates},
  year      = {2016},
  url       = {https://www.census.gov/programs-surveys/acs/},
}

@inproceedings{agirre2009personalizing,
  title={Personalizing pagerank for word sense disambiguation},
  author={Agirre, Eneko and Soroa, Aitor},
  booktitle={Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={33--41},
  year={2009},
  organization={Association for Computational Linguistics}
}

@article{auerbach2018balancing,
  title={Balancing innovation and safety when integrating digital tools into health care},
  author={Auerbach, Andrew D and Neinstein, Aaron and Khanna, Raman},
  journal={Annals of internal medicine},
  volume={168},
  number={10},
  pages={733--734},
  year={2018},
  publisher={Am Coll Physicians}
}

@article{bobadilla2013recommender,
  title={Recommender systems survey},
  author={Bobadilla, Jes{\'u}s and Ortega, Fernando and Hernando, Antonio and Guti{\'e}rrez, Abraham},
  journal={Knowledge-Based Systems},
  volume={46},
  pages={109--132},
  year={2013},
  publisher={Elsevier}
}

@article{bojarski2016end,
  title={End-to-end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{cabitza2017unintended,
  title={Unintended consequences of machine learning in medicine},
  author={Cabitza, Federico and Rasoini, Raffaele and Gensini, Gian Franco},
  journal={Jama},
  volume={318},
  number={6},
  pages={517--518},
  year={2017},
  publisher={American Medical Association}
}

@article{castelvecchi2016can,
  title={Can we open the black box of AI?},
  author={Castelvecchi, Davide},
  journal={Nature News},
  volume={538},
  number={7623},
  pages={20},
  year={2016}
}

@article{chai2014root,
  title={Root mean square error (RMSE) or mean absolute error (MAE)?--Arguments against avoiding RMSE in the literature},
  author={Chai, Tianfeng and Draxler, Roland R},
  journal={Geoscientific model development},
  volume={7},
  number={3},
  pages={1247--1250},
  year={2014},
  publisher={Copernicus GmbH}
}

@article{coudray2018classification,
  title={Classification and mutation prediction from non--small cell lung cancer histopathology images using deep learning},
  author={Coudray, Nicolas and Ocampo, Paolo Santiago and Sakellaropoulos, Theodore and Narula, Navneet and Snuderl, Matija and Feny{\"o}, David and Moreira, Andre L and Razavian, Narges and Tsirigos, Aristotelis},
  journal={Nature Medicine},
  volume={24},
  number={10},
  pages={1559},
  year={2018},
  publisher={Nature Publishing Group}
}

@book{esl,
  author    = {Trevor Hastie and
               Robert Tibshirani and
               Jerome H. Friedman},
  title     = {The elements of statistical learning: data mining, inference, and
               prediction, 2nd Edition},
  series    = {Springer Series in Statistics},
  publisher = {Springer},
  year      = {2009},
  url       = {http://www.worldcat.org/oclc/300478243},
  isbn      = {9780387848570},
  timestamp = {Wed, 03 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/bib/books/lib/HastieTF09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{esteva2017dermatologist,
  title={Dermatologist-level classification of skin cancer with deep neural networks},
  author={Esteva, Andre and Kuprel, Brett and Novoa, Roberto A and Ko, Justin and Swetter, Susan M and Blau, Helen M and Thrun, Sebastian},
  journal={Nature},
  volume={542},
  number={7639},
  pages={115},
  year={2017},
  publisher={Nature Publishing Group}
}

@Article{gbmtutorial,
AUTHOR={Natekin, Alexey and Knoll, Alois},   
TITLE={Gradient boosting machines, a tutorial},      
JOURNAL={Frontiers in Neurorobotics},      
VOLUME={7},     
PAGES={21},     
YEAR={2013},        
URL={https://www.frontiersin.org/article/10.3389/fnbot.2013.00021},       
DOI={10.3389/fnbot.2013.00021},      
ISSN={1662-5218},    
ABSTRACT={Gradient boosting machines are a family of powerful machine-learning techniques that have shown considerable success in a wide range of practical applications. They are highly customizable to the particular needs of the application, like being learned with respect to different loss functions. This article gives a tutorial introduction into the methodology of gradient boosting methods. A theoretical information is complemented with many descriptive examples and illustrations which cover all the stages of the gradient boosting model design. Considerations on handling the model complexity are discussed. A set of practical examples of gradient boosting applications are presented and comprehensively analyzed.
}
}

@article{gulshan2016development,
  title={Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs},
  author={Gulshan, Varun and Peng, Lily and Coram, Marc and Stumpe, Martin C and Wu, Derek and Narayanaswamy, Arunachalam and Venugopalan, Subhashini and Widner, Kasumi and Madams, Tom and Cuadros, Jorge and others},
  journal={JAMA},
  volume={316},
  number={22},
  pages={2402--2410},
  year={2016},
  publisher={American Medical Association}
}

@Comment{jabref-meta: databaseType:biblatex;}


@article{krumholz2017,
	doi = {10.1056/nejmsa1702321},
	url = {https://doi.org/10.1056%2Fnejmsa1702321},
	year = 2017,
	month = {sep},
	publisher = {Massachusetts Medical Society},
	volume = {377},
	number = {11},
	pages = {1055--1064},
	author = {Harlan M. Krumholz and Kun Wang and Zhenqiu Lin and Kumar Dharmarajan and Leora I. Horwitz and Joseph S. Ross and Elizabeth E. Drye and Susannah M. Bernheim and Sharon-Lise T. Normand},
	title = {Hospital-Readmission Risk {\textemdash} Isolating Hospital Effects from Patient Effects},
	journal = {New England Journal of Medicine}
}

@incollection{lightgbm,
  title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
  author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  booktitle = {Advances in Neural Information Processing Systems 30},
  editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages = {3146--3154},
  year = {2017},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf}
}

@incollection{lundberg2017unified,
  title = {A Unified Approach to Interpreting Model Predictions},
  author = {Lundberg, Scott M and Lee, Su-In},
  booktitle = {Advances in Neural Information Processing Systems 30},
  editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages = {4765--4774},
  year = {2017},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@misc{lundberg2018consistent,
  title={Consistent Individualized Feature Attribution for Tree Ensembles},
  author={Scott M. Lundberg and Gabriel G. Erion and Su-In Lee},
  year={2018},
  eprint={1802.03888},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@article{lundberg2018explainable,
  title={Explainable machine-learning predictions for the prevention of hypoxaemia during surgery},
  author={Lundberg, Scott M and Nair, Bala and Vavilala, Monica S and Horibe, Mayumi and Eisses, Michael J and Adams, Trevor and Liston, David E and Low, Daniel King-Wai and Newman, Shu-Fang and Kim, Jerry and others},
  journal={Nature Biomedical Engineering},
  volume={2},
  number={10},
  pages={749},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{lundberg2019explainable,
    title={Explainable AI for Trees: From Local Explanations to Global Understanding},
    author={Scott M. Lundberg and Gabriel Erion and Hugh Chen and Alex DeGrave and Jordan M. Prutkin and Bala Nair and Ronit Katz and Jonathan Himmelfarb and Nisha Bansal and Su-In Lee},
    year={2019},
    eprint={1905.04610},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python
  for application development, interactive scripting, and
  publication-quality image generation across user
  interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@misc{matplotlib2tikz,
  author       = {Nico Schlömer and
      danielhkl and
      Armin Wehrfritz and
      Holger Berndt and
      Spyros Stathopoulos and
      Christoph Boeddeker and
      Daniel Edler and
      Andrew Spott and
      André Gaul and
      Marco Rossi and
      Benoît Vinot and
      Dominik Schürmann and
      Moritz Lipp and
      Douglas Dawson and
      mrtnschltr and
      pwohlhart and
      hgwd2 and
      Sebastian Koslowski and
      Patrick Lacasse and
      Olivier Verdier and
      David Haberthür and
      Alexey Kuzmin},
  title        = {nschloe/matplotlib2tikz v0.7.3},
  month        = feb,
  year         = 2018,
  doi          = {10.5281/zenodo.1173090},
  url          = {https://doi.org/10.5281/zenodo.1173090}
}

@article{obs2016nejm,
author = {Zuckerman, Rachael B. and Sheingold, Steven H. and Orav, E. John and Ruhter, Joel and Epstein, Arnold M.},
title = {Readmissions, Observation, and the Hospital Readmissions Reduction Program},
journal = {New England Journal of Medicine},
volume = {374},
number = {16},
pages = {1543-1551},
year = {2016},
doi = {10.1056/NEJMsa1513024},
note ={PMID: 26910198},
URL = {https://doi.org/10.1056/NEJMsa1513024},
eprint = {https://doi.org/10.1056/NEJMsa1513024}
}

@article{obsincreasing2019,
author = {Keith D. Lind and Claire M. Noel-Miller and Lindsey R. Sangaralingham and Nilay D. Shah and Erik P. Hess and Pamela Morin and M. Fernanda Bellolio},
title ={Increasing Trends in the Use of Hospital Observation Services for Older Medicare Advantage and Privately Insured Patients},
journal = {Medical Care Research and Review},
volume = {76},
number = {2},
pages = {229-239},
year = {2019},
doi = {10.1177/1077558717718026},
note ={PMID: 29148348},
URL = {https://doi.org/10.1177/1077558717718026   },
eprint = {https://doi.org/10.1177/1077558717718026},
abstract = { Policy and financial pressures have driven up use of observation stays for patients in traditional Medicare and the Veterans’ Affairs Healthcare System. Using claims data (2004-2014) from OptumLabs™ Data Warehouse, we examined whether people in private Medicare Advantage (MA) and commercial plans experienced similar changes. We found that use of observation increased rapidly for patients in MA plans—even though MA plans were not subject to the same pressures as government-run programs. In contrast, use of observation remained constant for people in commercial plans—except for enrollees 65 and older, for whom it increased somewhat. Privately insured patients returning to the hospital after an inpatient stay were increasingly likely to be placed under observation. Our results suggest that observation is rapidly replacing inpatient admissions and readmissions for many older patients in MA and commercial plans, while younger patients continue to be admitted as inpatients at relatively constant rates. }
}

@article{pencina2015evaluating,
  title={Evaluating discrimination of risk prediction models: the C statistic},
  author={Pencina, Michael J and D’Agostino, Ralph B},
  journal={Jama},
  volume={314},
  number={10},
  pages={1063--1064},
  year={2015},
  publisher={American Medical Association}
}

@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
      and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
      and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
      Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{sniderman2015role,
  title={The role of physicians in the era of predictive analytics},
  author={Sniderman, Allan D and D’Agostino Sr, Ralph B and Pencina, Michael J},
  journal={Jama},
  volume={314},
  number={1},
  pages={25--26},
  year={2015},
  publisher={American Medical Association}
}

@article{sun2017unreasonable,
  author    = {Chen Sun and
               Abhinav Shrivastava and
               Saurabh Singh and
               Abhinav Gupta},
  title     = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},
  journal   = {CoRR},
  volume    = {abs/1707.02968},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.02968},
  archivePrefix = {arXiv},
  eprint    = {1707.02968},
  timestamp = {Fri, 05 Apr 2019 07:29:46 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SunSSG17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhang2005boosting,
  title={Boosting with early stopping: Convergence and consistency},
  author={Zhang, Tong and Yu, Bin and others},
  journal={The Annals of Statistics},
  volume={33},
  number={4},
  pages={1538--1579},
  year={2005},
  publisher={Institute of Mathematical Statistics}
}

